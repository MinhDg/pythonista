{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  JSON =  the JavaScript object notation\n",
    "\n",
    "# use Python to connect to a real time JSON data feed out on the internet and process the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Example file for parsing and processing JSON\n",
    "#\n",
    "import urllib.request \n",
    "import json # import the correct module\n",
    "\n",
    "def printResults(data):\n",
    "    theJSON = json.loads(data) # Use the json module to load the string data into a dictionary\n",
    "    \n",
    "    # now we can access the contents of the JSON like any other Python object\n",
    "    if \"title\" in theJSON[\"metadata\"]:\n",
    "        print(theJSON[\"metadata\"][\"title\"])\n",
    "    \n",
    "    # output the number of events, plus the magnitude and each event name\n",
    "    count = theJSON[\"metadata\"][\"title\"]\n",
    "    print(str(count) + \"events recorded\")\n",
    "\n",
    "  # for each event, print the place where it occurred\n",
    "\n",
    "\n",
    "  # print the events that only have a magnitude greater than 4\n",
    "\n",
    "      \n",
    "  # print only the events where at least 1 person reported feeling something\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-14-03ee42e7b94b>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-14-03ee42e7b94b>\"\u001b[1;36m, line \u001b[1;32m43\u001b[0m\n\u001b[1;33m    urlData = \"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_day.geojson\"\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Example file for parsing and processing JSON\n",
    "#\n",
    "\n",
    "import urllib.request # instead of urllib2 like in Python 2.7\n",
    "import json\n",
    "\n",
    "def printResults(data):\n",
    "  # Use the json module to load the string data into a dictionary\n",
    "  theJSON = json.loads(data) # calling the loads function on the json class and assigned a result to a variable names theJSON\n",
    "  \n",
    "  # now we can access the contents of the JSON like any other Python object\n",
    "  if \"title\" in theJSON[\"metadata\"]:\n",
    "    print (theJSON[\"metadata\"][\"title\"])\n",
    "  \n",
    "  # output the number of events, plus the magnitude and each event name  \n",
    "  count = theJSON[\"metadata\"][\"count\"];\n",
    "  print (str(count) + \" events recorded\")\n",
    "  \n",
    "  # for each event, print the place where it occurred\n",
    "  for i in theJSON[\"features\"]:\n",
    "    print (i[\"properties\"][\"place\"])\n",
    "  print (\"--------------\\n\")\n",
    "\n",
    "  # print the events that only have a magnitude greater than 4\n",
    "  for i in theJSON[\"features\"]:\n",
    "    if i[\"properties\"][\"mag\"] >= 4.0:\n",
    "      print (\"%2.1f\" % i[\"properties\"][\"mag\"], i[\"properties\"][\"place\"])\n",
    "  print (\"--------------\\n\")\n",
    "\n",
    "  # print only the events where at least 1 person reported feeling something\n",
    "  print (\"\\n\\nEvents that were felt:\")\n",
    "  for i in theJSON[\"features\"]:\n",
    "    feltReports = i[\"properties\"][\"felt\"]\n",
    "    if (feltReports != None):\n",
    "      if (feltReports > 0):\n",
    "        print (\"%2.1f\" % i[\"properties\"][\"mag\"], i[\"properties\"][\"place\"], \" reported \" + str(feltReports) + \" times\")\n",
    "  \n",
    "def main():\n",
    "  # define a variable to hold the source URL\n",
    "  # In this case we'll use the free data feed from the USGS\n",
    "  # This feed lists all earthquakes for the last day larger than Mag 2.5\n",
    "  urlData = \"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_day.geojson\"\n",
    "  \n",
    "  # Open the URL and read the data\n",
    "  webUrl = urllib.request.urlopen(urlData)\n",
    "  print (\"result code: \" + str(webUrl.getcode()))\n",
    "  if (webUrl.getcode() == 200):\n",
    "    data = webUrl.read()\n",
    "    # print out our customized results\n",
    "    printResults(data)\n",
    "  else:\n",
    "    print (\"Received an error from server, cannot retrieve results \" + str(webUrl.getcode()))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result code: 200\n",
      "USGS Magnitude 2.5+ Earthquakes, Past Day\n",
      "42 events recorded\n"
     ]
    }
   ],
   "source": [
    "import urllib.request # instead of urllib2 like in Python 2.7\n",
    "import json\n",
    "\n",
    "def printResults(data):\n",
    "  # Use the json module to load the string data into a dictionary\n",
    "  theJSON = json.loads(data) # calling the loads function on the json class and assigned a result to a variable names theJSON\n",
    "  \n",
    "  # now we can access the contents of the JSON like any other Python object\n",
    "  if \"title\" in theJSON[\"metadata\"]:\n",
    "    print (theJSON[\"metadata\"][\"title\"])\n",
    "  \n",
    "  # output the number of events, plus the magnitude and each event name  \n",
    "  count = theJSON[\"metadata\"][\"count\"];\n",
    "  print (str(count) + \" events recorded\")\n",
    "\n",
    "def main():\n",
    "  # define a variable to hold the source URL\n",
    "  # In this case we'll use the free data feed from the USGS\n",
    "  # This feed lists all earthquakes for the last day larger than Mag 2.5\n",
    "  urlData = \"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_day.geojson\"\n",
    "  \n",
    "  # Open the URL and read the data\n",
    "  webUrl = urllib.request.urlopen(urlData)\n",
    "  print (\"result code: \" + str(webUrl.getcode()))\n",
    "  if (webUrl.getcode() == 200):\n",
    "    data = webUrl.read()\n",
    "    # print out our customized results\n",
    "    printResults(data)\n",
    "  else:\n",
    "    print (\"Received an error from server, cannot retrieve results \" + str(webUrl.getcode()))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result code: 200\n",
      "6 km S of Hennessey, Oklahoma\n",
      "37 km SE of Mina, Nevada\n",
      "201 km NW of Kiunga, Papua New Guinea\n",
      "29 km SE of Khorugh, Tajikistan\n",
      "87 km WNW of Naisano Dua, Indonesia\n",
      "1 km WNW of Tallaboa, Puerto Rico\n",
      "40 km SE of Mina, Nevada\n",
      "1 km SSW of Magas Arriba, Puerto Rico\n",
      "89 km S of Néa Anatolí, Greece\n",
      "62 km S of Puerto San José, Guatemala\n",
      "4 km SSE of Maria Antonia, Puerto Rico\n",
      "30km SE of Bodie, CA\n",
      "5 km SSE of Maria Antonia, Puerto Rico\n",
      "29 km SSE of Mina, Nevada\n",
      "6km NNE of Lake Henshaw, CA\n",
      "75 km SSW of Puerto San José, Guatemala\n",
      "1 km NW of Tallaboa, Puerto Rico\n",
      "14km S of Searles Valley, CA\n",
      "37 km SE of Mina, Nevada\n",
      "36 km ESE of Mina, Nevada\n",
      "34 km SE of Mina, Nevada\n",
      "5 km SSE of Guánica, Puerto Rico\n",
      "150 km SE of Baruun-Urt, Mongolia\n",
      "165 km SE of Gorontalo, Indonesia\n",
      "32 km SSE of Mina, Nevada\n",
      "54 km WSW of Nikolski, Alaska\n",
      "36 km SE of Mina, Nevada\n",
      "29 km SSE of Mina, Nevada\n",
      "6 km SSE of Maria Antonia, Puerto Rico\n",
      "39 km SE of Mina, Nevada\n",
      "37 km SE of Mina, Nevada\n",
      "7 km N of Ames, Oklahoma\n",
      "52 km SW of San Pedro de Atacama, Chile\n",
      "8 km SSE of Maria Antonia, Puerto Rico\n",
      "32 km SE of Mina, Nevada\n",
      "29 km SSE of Mina, Nevada\n",
      "131 km SSW of Kokopo, Papua New Guinea\n",
      "6 km W of Point Possession, Alaska\n",
      "84 km NNW of Port-Vila, Vanuatu\n",
      "2 km ESE of Magas Arriba, Puerto Rico\n",
      "2km SE of Lake Henshaw, CA\n",
      "110 km SE of Attu Station, Alaska\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Example file for parsing and processing JSON\n",
    "#\n",
    "\n",
    "import urllib.request # instead of urllib2 like in Python 2.7\n",
    "import json\n",
    "\n",
    "def printResults(data):\n",
    "  # Use the json module to load the string data into a dictionary\n",
    "  theJSON = json.loads(data)\n",
    "\n",
    "  # for each event, print the place where it occurred\n",
    "  for i in theJSON[\"features\"]:\n",
    "    print (i[\"properties\"][\"place\"])\n",
    "  print (\"--------------\\n\")\n",
    " \n",
    "def main():\n",
    "  # define a variable to hold the source URL\n",
    "  # In this case we'll use the free data feed from the USGS\n",
    "  # This feed lists all earthquakes for the last day larger than Mag 2.5\n",
    "  urlData = \"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_day.geojson\"\n",
    "  \n",
    "  # Open the URL and read the data\n",
    "  webUrl = urllib.request.urlopen(urlData)\n",
    "  print (\"result code: \" + str(webUrl.getcode()))\n",
    "  if (webUrl.getcode() == 200):\n",
    "    data = webUrl.read()\n",
    "    # print out our customized results\n",
    "    printResults(data)\n",
    "  else:\n",
    "    print (\"Received an error from server, cannot retrieve results \" + str(webUrl.getcode()))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result code: 200\n",
      "4.6 12 km WSW of Mamurras, Albania\n",
      "4.4 201 km NW of Kiunga, Papua New Guinea\n",
      "4.2 29 km SE of Khorugh, Tajikistan\n",
      "4.7 87 km WNW of Naisano Dua, Indonesia\n",
      "4.1 89 km S of Néa Anatolí, Greece\n",
      "4.3 62 km S of Puerto San José, Guatemala\n",
      "4.6 75 km SSW of Puerto San José, Guatemala\n",
      "4.3 14km S of Searles Valley, CA\n",
      "4.8 34 km SE of Mina, Nevada\n",
      "4.3 150 km SE of Baruun-Urt, Mongolia\n",
      "5.0 165 km SE of Gorontalo, Indonesia\n",
      "4.8 52 km SW of San Pedro de Atacama, Chile\n",
      "5.9 131 km SSW of Kokopo, Papua New Guinea\n",
      "4.8 84 km NNW of Port-Vila, Vanuatu\n",
      "4.1 110 km SE of Attu Station, Alaska\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Example file for parsing and processing JSON\n",
    "#\n",
    "\n",
    "import urllib.request # instead of urllib2 like in Python 2.7\n",
    "import json\n",
    "\n",
    "def printResults(data):\n",
    "  # Use the json module to load the string data into a dictionary\n",
    "  theJSON = json.loads(data)\n",
    "  \n",
    "  # print the events that only have a magnitude greater than 4\n",
    "  for i in theJSON[\"features\"]:\n",
    "    if i[\"properties\"][\"mag\"] >= 4.0:\n",
    "      print (\"%2.1f\" % i[\"properties\"][\"mag\"], i[\"properties\"][\"place\"]) #  percent 2.1 F. \n",
    "    # That formats a decimal with 2.1 spaces. So two significant digits and one decimal digit \n",
    "  print (\"--------------\\n\") # print a dividing line to separate the results.\n",
    " \n",
    "def main():\n",
    "  # define a variable to hold the source URL\n",
    "  # In this case we'll use the free data feed from the USGS\n",
    "  # This feed lists all earthquakes for the last day larger than Mag 2.5\n",
    "  urlData = \"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_day.geojson\"\n",
    "  \n",
    "  # Open the URL and read the data\n",
    "  webUrl = urllib.request.urlopen(urlData)\n",
    "  print (\"result code: \" + str(webUrl.getcode()))\n",
    "  if (webUrl.getcode() == 200):\n",
    "    data = webUrl.read()\n",
    "    # print out our customized results\n",
    "    printResults(data)\n",
    "  else:\n",
    "    print (\"Received an error from server, cannot retrieve results \" + str(webUrl.getcode()))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result code: 200\n",
      "\n",
      "\n",
      "Events that were felt:\n",
      "3.6 29 km SSE of Mina, Nevada  reported 3 times\n",
      "2.5 6km NNE of Lake Henshaw, CA  reported 2 times\n",
      "4.3 14km S of Searles Valley, CA  reported 291 times\n",
      "4.8 34 km SE of Mina, Nevada  reported 49 times\n",
      "2.9 7 km N of Ames, Oklahoma  reported 1 times\n",
      "3.2 32 km SE of Mina, Nevada  reported 2 times\n",
      "5.9 131 km SSW of Kokopo, Papua New Guinea  reported 3 times\n",
      "3.0 6 km W of Point Possession, Alaska  reported 1 times\n",
      "2.6 2km SE of Lake Henshaw, CA  reported 11 times\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Example file for parsing and processing JSON\n",
    "#\n",
    "\n",
    "import urllib.request # instead of urllib2 like in Python 2.7\n",
    "import json\n",
    "\n",
    "def printResults(data):\n",
    "  # Use the json module to load the string data into a dictionary\n",
    "  theJSON = json.loads(data)\n",
    "\n",
    "  # print only the events where at least 1 person reported feeling something\n",
    "  print (\"\\n\\nEvents that were felt:\")\n",
    "  for i in theJSON[\"features\"]:\n",
    "    feltReports = i[\"properties\"][\"felt\"]\n",
    "    if (feltReports != None):\n",
    "      if (feltReports > 0):\n",
    "        print (\"%2.1f\" % i[\"properties\"][\"mag\"], i[\"properties\"][\"place\"], \" reported \" + str(feltReports) + \" times\")\n",
    "  \n",
    "  \n",
    "def main():\n",
    "  # define a variable to hold the source URL\n",
    "  # In this case we'll use the free data feed from the USGS\n",
    "  # This feed lists all earthquakes for the last day larger than Mag 2.5\n",
    "  urlData = \"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_day.geojson\"\n",
    "  \n",
    "  # Open the URL and read the data\n",
    "  webUrl = urllib.request.urlopen(urlData)\n",
    "  print (\"result code: \" + str(webUrl.getcode()))\n",
    "  if (webUrl.getcode() == 200):\n",
    "    data = webUrl.read()\n",
    "    # print out our customized results\n",
    "    printResults(data)\n",
    "  else:\n",
    "    print (\"Received an error from server, cannot retrieve results \" + str(webUrl.getcode()))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
